{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating wrong choices for MCQs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWjuxtD_1VBY",
        "outputId": "86b81c49-fc93-4538-bebb-b818b6cd7c58"
      },
      "source": [
        "!pip install nltk==3.5.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk==3.5.0 in /usr/local/lib/python3.7/dist-packages (3.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.5.0) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.5.0) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5.0) (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEyymMjp1aaq",
        "outputId": "87979cf2-aaba-4712-d5ee-98d0bc29380f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxUIQAhQ3bVC",
        "outputId": "a680ad74-da06-4a12-828e-5cb37a2828b3"
      },
      "source": [
        "word = 'nile'\n",
        "word = word.lower()\n",
        "syns = wn.synsets(word)\n",
        "for syn in syns:\n",
        "  print(syn,':',syn.definition(),'\\n')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Synset('nile.n.01') : the world's longest river (4150 miles); flows northward through eastern Africa into the Mediterranean; the Nile River valley in Egypt was the site of the world's first great civilization \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29cDeLpN1yGD",
        "outputId": "2559050c-d565-4e50-9689-68eca26cac2f"
      },
      "source": [
        "word = 'bat'\n",
        "word = word.lower()\n",
        "syns = wn.synsets(word)\n",
        "for syn in syns:\n",
        "  print(syn,':',syn.definition(),'\\n')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Synset('bat.n.01') : nocturnal mouselike mammal with forelimbs modified to form membranous wings and anatomical adaptations for echolocation by which they navigate \n",
            "\n",
            "Synset('bat.n.02') : (baseball) a turn trying to get a hit \n",
            "\n",
            "Synset('squash_racket.n.01') : a small racket with a long handle used for playing squash \n",
            "\n",
            "Synset('cricket_bat.n.01') : the club used in playing cricket \n",
            "\n",
            "Synset('bat.n.05') : a club used for hitting a ball in various games \n",
            "\n",
            "Synset('bat.v.01') : strike with, or as if with a baseball bat \n",
            "\n",
            "Synset('bat.v.02') : wink briefly \n",
            "\n",
            "Synset('bat.v.03') : have a turn at bat \n",
            "\n",
            "Synset('bat.v.04') : use a bat \n",
            "\n",
            "Synset('cream.v.02') : beat thoroughly and conclusively in a competition or fight \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMjlmJ_p2K0X",
        "outputId": "2d48a4fd-230c-4639-b6a9-04574257d628"
      },
      "source": [
        "word = 'bat'\n",
        "word = word.lower()\n",
        "syns = wn.synsets(word,'n')\n",
        "for syn in syns:\n",
        "  print(syn,':',syn.definition(),'\\n')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Synset('bat.n.01') : nocturnal mouselike mammal with forelimbs modified to form membranous wings and anatomical adaptations for echolocation by which they navigate \n",
            "\n",
            "Synset('bat.n.02') : (baseball) a turn trying to get a hit \n",
            "\n",
            "Synset('squash_racket.n.01') : a small racket with a long handle used for playing squash \n",
            "\n",
            "Synset('cricket_bat.n.01') : the club used in playing cricket \n",
            "\n",
            "Synset('bat.n.05') : a club used for hitting a ball in various games \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7To9EpJW4hDF",
        "outputId": "5dfa645b-4b14-4e65-bd90-f04006fe3cb3"
      },
      "source": [
        "word = 'lion'\n",
        "word = word.lower()\n",
        "syns = wn.synsets(word,'n')\n",
        "\n",
        "hypernym = syns[0].hypernyms()\n",
        "print(hypernym)\n",
        "print(hypernym[0].hyponyms())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Synset('big_cat.n.01')]\n",
            "[Synset('cheetah.n.01'), Synset('jaguar.n.01'), Synset('leopard.n.02'), Synset('liger.n.01'), Synset('lion.n.01'), Synset('saber-toothed_tiger.n.01'), Synset('snow_leopard.n.01'), Synset('tiger.n.02'), Synset('tiglon.n.01')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiML1JYb5ceR"
      },
      "source": [
        "def generate_distractors(syn,word):\n",
        "  distractors = []\n",
        "  word = word.lower()\n",
        "  orig_word = word \n",
        "  if len(word.split())>0:\n",
        "    word = word.replace(' ','_')\n",
        "  hypernym = syn.hypernyms()\n",
        "  if len(hypernym)==0:\n",
        "    return distractors\n",
        "  for item in hypernym[0].hyponyms():\n",
        "    name = item.lemmas()[0].name()\n",
        "    if name == orig_word:\n",
        "      continue\n",
        "    name = name.replace('_',' ')\n",
        "    name = ' '.join(w.capitalize() for w in name.split())\n",
        "    if name is not None and name not in distractors:\n",
        "      distractors.append(name)\n",
        "  return distractors"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJCVV2bR9vQK",
        "outputId": "3c499236-1349-4f5a-dc72-ce5681649b5b"
      },
      "source": [
        "word = 'lion'\n",
        "synset = wn.synsets(word,'n')[0]\n",
        "generate_distractors(synset, word)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cheetah',\n",
              " 'Jaguar',\n",
              " 'Leopard',\n",
              " 'Liger',\n",
              " 'Saber-toothed Tiger',\n",
              " 'Snow Leopard',\n",
              " 'Tiger',\n",
              " 'Tiglon']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FePYil_-KxN"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "import pprint"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG_vwyiNr_F8",
        "outputId": "f17c78ea-4c35-4edf-f0b5-6e446e06abc0"
      },
      "source": [
        "word = 'California'\n",
        "word = word.lower()\n",
        "if (len(word.split())>0):\n",
        "  word = word.replace(' ','_')\n",
        "\n",
        "url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
        "obj = requests.get(url).json()\n",
        "\n",
        "pprint.pprint(obj)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'@context': ['http://api.conceptnet.io/ld/conceptnet5.7/context.ld.json'],\n",
            " '@id': '/query?node=/c/en/california/n&rel=/r/PartOf&start=/c/en/california',\n",
            " 'edges': [{'@id': '/a/[/r/PartOf/,/c/en/california/n/wn/location/,/c/en/southwest/n/wn/location/]',\n",
            "            '@type': 'Edge',\n",
            "            'dataset': '/d/wordnet/3.1',\n",
            "            'end': {'@id': '/c/en/southwest/n/wn/location',\n",
            "                    '@type': 'Node',\n",
            "                    'label': 'Southwest',\n",
            "                    'language': 'en',\n",
            "                    'sense_label': 'n, location',\n",
            "                    'term': '/c/en/southwest'},\n",
            "            'license': 'cc:by/4.0',\n",
            "            'rel': {'@id': '/r/PartOf', '@type': 'Relation', 'label': 'PartOf'},\n",
            "            'sources': [{'@id': '/s/resource/wordnet/rdf/3.1',\n",
            "                         '@type': 'Source',\n",
            "                         'contributor': '/s/resource/wordnet/rdf/3.1'}],\n",
            "            'start': {'@id': '/c/en/california/n/wn/location',\n",
            "                      '@type': 'Node',\n",
            "                      'label': 'California',\n",
            "                      'language': 'en',\n",
            "                      'sense_label': 'n, location',\n",
            "                      'term': '/c/en/california'},\n",
            "            'surfaceText': '[[California]] is a part of [[Southwest]]',\n",
            "            'weight': 2.0},\n",
            "           {'@id': '/a/[/r/PartOf/,/c/en/california/n/wn/location/,/c/en/united_states/n/wn/location/]',\n",
            "            '@type': 'Edge',\n",
            "            'dataset': '/d/wordnet/3.1',\n",
            "            'end': {'@id': '/c/en/united_states/n/wn/location',\n",
            "                    '@type': 'Node',\n",
            "                    'label': 'United States',\n",
            "                    'language': 'en',\n",
            "                    'sense_label': 'n, location',\n",
            "                    'term': '/c/en/united_states'},\n",
            "            'license': 'cc:by/4.0',\n",
            "            'rel': {'@id': '/r/PartOf', '@type': 'Relation', 'label': 'PartOf'},\n",
            "            'sources': [{'@id': '/s/resource/wordnet/rdf/3.1',\n",
            "                         '@type': 'Source',\n",
            "                         'contributor': '/s/resource/wordnet/rdf/3.1'}],\n",
            "            'start': {'@id': '/c/en/california/n/wn/location',\n",
            "                      '@type': 'Node',\n",
            "                      'label': 'California',\n",
            "                      'language': 'en',\n",
            "                      'sense_label': 'n, location',\n",
            "                      'term': '/c/en/california'},\n",
            "            'surfaceText': '[[California]] is a part of [[United States]]',\n",
            "            'weight': 2.0}],\n",
            " 'version': '5.8.1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-paw81Et6M_",
        "outputId": "ea890ee4-254c-46ff-aa9b-e6d011f95761"
      },
      "source": [
        "for edge in obj['edges']:\n",
        "  link = edge['end']['term']\n",
        "  print(link)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/c/en/southwest\n",
            "/c/en/united_states\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IFwart4y_a7",
        "outputId": "a08f4c23-8044-4dce-e82b-d92b7a22962c"
      },
      "source": [
        "word = \"California\"\n",
        "word = word.lower()\n",
        "if (len(word.split())>0):\n",
        "  word = word.replace(\" \",\"_\")\n",
        "\n",
        "\n",
        "# url = \"http://api.conceptnet.io/query?node=/c/en/%s/n\"%(word)\n",
        "# url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf\"%(word)\n",
        "url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s\"%(word,word)\n",
        "obj = requests.get(url).json()\n",
        "\n",
        "pprint.pprint (obj)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'@context': ['http://api.conceptnet.io/ld/conceptnet5.7/context.ld.json'],\n",
            " '@id': '/query?node=/c/en/california/n&rel=/r/PartOf&start=/c/en/california',\n",
            " 'edges': [{'@id': '/a/[/r/PartOf/,/c/en/california/n/wn/location/,/c/en/southwest/n/wn/location/]',\n",
            "            '@type': 'Edge',\n",
            "            'dataset': '/d/wordnet/3.1',\n",
            "            'end': {'@id': '/c/en/southwest/n/wn/location',\n",
            "                    '@type': 'Node',\n",
            "                    'label': 'Southwest',\n",
            "                    'language': 'en',\n",
            "                    'sense_label': 'n, location',\n",
            "                    'term': '/c/en/southwest'},\n",
            "            'license': 'cc:by/4.0',\n",
            "            'rel': {'@id': '/r/PartOf', '@type': 'Relation', 'label': 'PartOf'},\n",
            "            'sources': [{'@id': '/s/resource/wordnet/rdf/3.1',\n",
            "                         '@type': 'Source',\n",
            "                         'contributor': '/s/resource/wordnet/rdf/3.1'}],\n",
            "            'start': {'@id': '/c/en/california/n/wn/location',\n",
            "                      '@type': 'Node',\n",
            "                      'label': 'California',\n",
            "                      'language': 'en',\n",
            "                      'sense_label': 'n, location',\n",
            "                      'term': '/c/en/california'},\n",
            "            'surfaceText': '[[California]] is a part of [[Southwest]]',\n",
            "            'weight': 2.0},\n",
            "           {'@id': '/a/[/r/PartOf/,/c/en/california/n/wn/location/,/c/en/united_states/n/wn/location/]',\n",
            "            '@type': 'Edge',\n",
            "            'dataset': '/d/wordnet/3.1',\n",
            "            'end': {'@id': '/c/en/united_states/n/wn/location',\n",
            "                    '@type': 'Node',\n",
            "                    'label': 'United States',\n",
            "                    'language': 'en',\n",
            "                    'sense_label': 'n, location',\n",
            "                    'term': '/c/en/united_states'},\n",
            "            'license': 'cc:by/4.0',\n",
            "            'rel': {'@id': '/r/PartOf', '@type': 'Relation', 'label': 'PartOf'},\n",
            "            'sources': [{'@id': '/s/resource/wordnet/rdf/3.1',\n",
            "                         '@type': 'Source',\n",
            "                         'contributor': '/s/resource/wordnet/rdf/3.1'}],\n",
            "            'start': {'@id': '/c/en/california/n/wn/location',\n",
            "                      '@type': 'Node',\n",
            "                      'label': 'California',\n",
            "                      'language': 'en',\n",
            "                      'sense_label': 'n, location',\n",
            "                      'term': '/c/en/california'},\n",
            "            'surfaceText': '[[California]] is a part of [[United States]]',\n",
            "            'weight': 2.0}],\n",
            " 'version': '5.8.1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iToLGHSuvwDb",
        "outputId": "5218bf1b-5569-4587-fdf1-4d9a0f8eef76"
      },
      "source": [
        "\n",
        "for edge in obj['edges']:\n",
        "  link = edge['end']['term'] \n",
        "  print (link)\n",
        "  distractor_list = []\n",
        "  url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
        "  obj2 = requests.get(url2).json()\n",
        "  for edge in obj2['edges']:\n",
        "      word2 = edge['start']['label']\n",
        "      if word2 not in distractor_list and word.lower() not in word2.lower():\n",
        "          distractor_list.append(word2)\n",
        "  print (distractor_list)\n",
        "  print (\"\\n\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/c/en/southwest\n",
            "['Texas', 'Arizona', 'New Mexico', 'Nevada']\n",
            "\n",
            "\n",
            "/c/en/united_states\n",
            "['Kansas', 'New England', 'Florida', 'Montana', 'Twin', 'Alabama', 'Yosemite', 'Connecticut', 'Mid-Atlantic states', 'New Mexico']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJfNkTeoyNfi",
        "outputId": "3c911fd8-e335-419a-b867-5495a9ff16ca"
      },
      "source": [
        "# putting everything together\n",
        "# Distractors from http://conceptnet.io/\n",
        "def get_distractors_conceptnet(word):\n",
        "    word = word.lower()\n",
        "    original_word= word\n",
        "    if (len(word.split())>0):\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    distractor_list = [] \n",
        "    url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
        "    obj = requests.get(url).json()\n",
        "\n",
        "    for edge in obj['edges']:\n",
        "        link = edge['end']['term'] \n",
        "\n",
        "        url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
        "        obj2 = requests.get(url2).json()\n",
        "        for edge in obj2['edges']:\n",
        "            word2 = edge['start']['label']\n",
        "            if word2 not in distractor_list and original_word.lower() not in word2.lower():\n",
        "                distractor_list.append(word2)\n",
        "                   \n",
        "    return distractor_list\n",
        "\n",
        "original_word = \"California\"\n",
        "distractors = get_distractors_conceptnet(original_word)\n",
        "\n",
        "print (\"Original word: \",original_word)\n",
        "print (\"\\nDistractors \",distractors)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original word:  California\n",
            "\n",
            "Distractors  ['Texas', 'Arizona', 'New Mexico', 'Nevada', 'Kansas', 'New England', 'Florida', 'Montana', 'Twin', 'Alabama', 'Yosemite', 'Connecticut', 'Mid-Atlantic states']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7YDiv8ZzqYz",
        "outputId": "c8eced8c-cefe-46f1-85e5-5840edb44f18"
      },
      "source": [
        "!pip install sense2vec==1.0.2"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sense2vec==1.0.2 in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (3.8.1)\n",
            "Requirement already satisfied: catalogue>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (1.19.5)\n",
            "Requirement already satisfied: spacy<3.0.0,>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (0.8.2)\n",
            "Requirement already satisfied: srsly>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (1.0.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->sense2vec==1.0.2) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->sense2vec==1.0.2) (3.7.4.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (54.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmxn_iwk4XJd",
        "outputId": "9f3261e1-e9cd-40b5-f7d4-1bcb24b35824"
      },
      "source": [
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-13 16:41:18--  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210413%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210413T164118Z&X-Amz-Expires=300&X-Amz-Signature=95b471597a4eb13fa8e5ff12cf7bbf5ff451ae6fae729a303e886d8875173224&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-04-13 16:41:18--  https://github-releases.githubusercontent.com/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210413%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210413T164118Z&X-Amz-Expires=300&X-Amz-Signature=95b471597a4eb13fa8e5ff12cf7bbf5ff451ae6fae729a303e886d8875173224&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.110.154, 185.199.108.154, 185.199.111.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.110.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600444501 (573M) [application/octet-stream]\n",
            "Saving to: ‘s2v_reddit_2015_md.tar.gz.1’\n",
            "\n",
            "s2v_reddit_2015_md. 100%[===================>] 572.63M  62.1MB/s    in 13s     \n",
            "\n",
            "2021-04-13 16:41:31 (44.7 MB/s) - ‘s2v_reddit_2015_md.tar.gz.1’ saved [600444501/600444501]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4k0Gvj94aKw",
        "outputId": "ef95dd4f-0e5a-4121-f140-f159c092137b"
      },
      "source": [
        "!tar -xvf  s2v_reddit_2015_md.tar.gz"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./._s2v_old\n",
            "./s2v_old/\n",
            "./s2v_old/._freqs.json\n",
            "./s2v_old/freqs.json\n",
            "./s2v_old/._vectors\n",
            "./s2v_old/vectors\n",
            "./s2v_old/._cfg\n",
            "./s2v_old/cfg\n",
            "./s2v_old/._strings.json\n",
            "./s2v_old/strings.json\n",
            "./s2v_old/._key2row\n",
            "./s2v_old/key2row\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMCZd0Vm4dDc",
        "outputId": "f59f2c85-c7d8-4565-c804-0c3be9406981"
      },
      "source": [
        "!ls s2v_old"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cfg  freqs.json  key2row  strings.json\tvectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_fbn9kW4fP4"
      },
      "source": [
        "from sense2vec import Sense2Vec\n",
        "s2v = Sense2Vec().from_disk('s2v_old')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4I6s4FD4lAm",
        "outputId": "c4d0efb8-c736-4989-ee15-2682d9e64a8c"
      },
      "source": [
        "word = \"Donald Trump\"\n",
        "word = word.lower()\n",
        "word = word.replace(\" \", \"_\")\n",
        "\n",
        "print (\"word \",word)\n",
        "\n",
        "sense = s2v.get_best_sense(word)\n",
        "\n",
        "print (\"Best sense \",sense)\n",
        "most_similar = s2v.most_similar(sense, n=12)\n",
        "\n",
        "\n",
        "print (most_similar)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word  donald_trump\n",
            "Best sense  Donald_Trump|PERSON\n",
            "[('Sarah_Palin|PERSON', 0.8547), ('Mitt_Romney|PERSON', 0.8246), ('Barrack_Obama|PERSON', 0.8082), ('Bill_Clinton|PERSON', 0.8046), ('Oprah|GPE', 0.8042), ('Paris_Hilton|ORG', 0.7963), ('Palin|GPE', 0.7953), ('Oprah_Winfrey|PERSON', 0.7941), ('Stephen_Colbert|PERSON', 0.7927), ('Oprah|PERSON', 0.79), ('Hilary_Clinton|PERSON', 0.7896), ('Herman_Cain|PERSON', 0.787)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBfVOLAc4zCh",
        "outputId": "ff03ebbd-ade4-41bd-d3ec-379de1a7580f"
      },
      "source": [
        "distractors = []\n",
        "\n",
        "for each_word in most_similar:\n",
        "  append_word = each_word[0].split(\"|\")[0].replace(\"_\", \" \").lower()\n",
        "  if append_word.lower() != word:\n",
        "      distractors.append(append_word.title())\n",
        "\n",
        "print (distractors)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sarah Palin', 'Mitt Romney', 'Barrack Obama', 'Bill Clinton', 'Oprah', 'Paris Hilton', 'Palin', 'Oprah Winfrey', 'Stephen Colbert', 'Oprah', 'Hilary Clinton', 'Herman Cain']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n9Og7Ti47Og",
        "outputId": "31d71f23-272d-45ad-c4c9-cc13f486ac30"
      },
      "source": [
        "from collections import OrderedDict\n",
        "def sense2vec_get_words(word,s2v):\n",
        "    output = []\n",
        "    word = word.lower()\n",
        "    word = word.replace(\" \", \"_\")\n",
        "\n",
        "    sense = s2v.get_best_sense(word)\n",
        "    most_similar = s2v.most_similar(sense, n=20)\n",
        "\n",
        "    # print (\"most_similar \",most_similar)\n",
        "\n",
        "    for each_word in most_similar:\n",
        "        append_word = each_word[0].split(\"|\")[0].replace(\"_\", \" \").lower()\n",
        "        if append_word.lower() != word:\n",
        "            output.append(append_word.title())\n",
        "\n",
        "    out = list(OrderedDict.fromkeys(output))\n",
        "    return out\n",
        "\n",
        "word = \"Natural Language processing\"\n",
        "distractors = sense2vec_get_words(word,s2v)\n",
        "\n",
        "print (\"Distractors for \",word, \" : \")\n",
        "print (distractors)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distractors for  Natural Language processing  : \n",
            "['Machine Learning', 'Computer Vision', 'Deep Learning', 'Data Analysis', 'Neural Nets', 'Relational Databases', 'Algorithms', 'Neural Networks', 'Data Processing', 'Image Recognition', 'Nlp', 'Big Data', 'Data Science', 'Big Data Analysis', 'Information Retrieval', 'Speech Recognition', 'Programming Languages']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouGkU7y25VcV",
        "outputId": "42fba408-60a1-49b2-f0af-a7d27742327b"
      },
      "source": [
        "word = \"USA\"\n",
        "distractors = sense2vec_get_words(word,s2v)\n",
        "\n",
        "print (\"Distractors for \",word, \" : \")\n",
        "print (distractors)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distractors for  USA  : \n",
            "['Usa.', 'U.S', 'U.S.', 'Us.', 'Us', 'America', 'Canada', 'U.S.A', 'United States', 'Country', 'Only Country', 'Mexico', 'Other Countries', 'U.K.', 'Europe', 'U.S.A.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ4o6NZp5olL",
        "outputId": "da223333-ad13-4075-9973-00c5202d0f37"
      },
      "source": [
        "!pip install strsim==0.0.3"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: strsim==0.0.3 in /usr/local/lib/python3.7/dist-packages (0.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia5Zg31-BFeI",
        "outputId": "9fb25e78-6f41-403c-dbdb-ba6eb1bb4cb3"
      },
      "source": [
        "import string\n",
        "# A function to get all the edits for a word\n",
        "def edits(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz '+string.punctuation\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "print (edits(\"cat\"))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'kat', '>cat', 'ca,t', 'vat', 'c;t', 'cwat', 'c\"t', 'caut', 'ca\"', \"ca'\", 'scat', 'ca`t', 'cata', 'c{t', 'cxt', 'c/t', 'ca)', 'cat~', '/at', 'qcat', 'mcat', 'catj', 'cat%', 'rat', 'tat', 'c(at', 'ciat', '.at', 'ca&', 'c[t', 'ca\\\\t', 'catb', '\"at', 'dcat', 'c&t', 'cawt', 'ca(t', '*cat', 'tcat', '|cat', '~at', 'c$at', 'cat}', ',cat', 'catr', '/cat', 'cat@', 'lcat', 'cat|', 'caet', 'cau', 'ycat', 'ca@', 'jcat', 'cit', 'ca-', 'c<at', 'cat\"', 'wat', '{cat', 'coat', '`cat', 'cft', 'c@t', 'cat*', 'c!t', 'pat', 'ca=', 'c:at', 'caf', 'caqt', 'czt', 'ocat', 'cet', 'cac', 'ca}t', 'cat.', 'bcat', 'cnt', 'ckt', 'c}at', 'ucat', 'fat', 'c%at', '{at', 'vcat', 'c)t', 'at', 'ca^', '#at', 'ceat', 'kcat', 'xat', 'cae', 'catu', 'cat', '`at', 'cdt', 'dat', ' at', 'cab', 'cat]', 'bat', 'c]t', 'c*t', ' cat', 'ca@t', 'catz', '?cat', 'cjt', 'cpt', 'c[at', 'cajt', 'c+t', 'cat?', '-at', 'caot', 'ca-t', 'clt', 'cati', 'nat', 'zcat', 'cct', 'catn', 'caat', 'pcat', 'cay', 'c?at', 'c|t', 'ca[', 'act', 'c:t', 'ecat', 'csat', 'catg', 'c~at', 'c t', 'catt', 'ca~t', ';cat', 'hat', 'cart', 'ca+t', \"'cat\", 'c/at', 'ca.', 'camt', 'c~t', 'fcat', 'catl', 'cst', '=cat', 'cas', 'cat;', 'ca*', 'ca|t', 'cats', 'c$t', 'cav', '-cat', 'cat{', 'cak', 'ca:', 'c,t', 'cal', 'hcat', 'ca!t', 'ca~', '%cat', 'ca/', 'icat', '$cat', 'cah', 'catv', '(at', 'c_at', 'cabt', 'cath', 'c#at', 'c.at', ')cat', 'c at', 'jat', 'ca.t', 'xcat', '\\\\at', 'cam', 'cat>', '@at', 'catf', 'cat<', '@cat', 'cgat', ':cat', 'catq', 'cbt', '[at', 'cavt', 'yat', 'cakt', 'c\\\\t', '}cat', 'can', '~cat', 'cat_', 'c^at', 'caw', 'ca;', '(cat', 'ca%', 'cat,', 'cat=', 'oat', 'cai', 'c#t', ']at', \"'at\", 'ca]t', 'ca^t', ':at', 'gat', 'ca{', 'c^t', 'ca<t', 'qat', 'c{at', \"cat'\", 'sat', '_cat', 'cqat', 'calt', 'cat$', 'cagt', 'c.t', 'cant', 'cmat', \"c'at\", 'ca}', 'cayt', 'cat`', '!at', 'c\"at', 'cdat', '!cat', 'cvt', 'caj', 'cqt', 'c`at', '^at', 'c>at', 'eat', 'ca/t', 'c+at', 'catm', 'chat', 'cax', 'c,at', 'cat#', 'ca:t', 'ca>', 'ca_', '[cat', 'cgt', 'ca;t', 'ca&t', 'cat)', 'cfat', 'ca{t', 'uat', 'catw', 'cxat', 'caft', 'ca', 'ca\\\\', 'catk', 'acat', '&cat', 'caxt', 'ccat', 'caht', 'ca t', 'ctt', 'c?t', '=at', 'cait', 'zat', '_at', 'cap', 'ca#t', 'catd', 'c;at', 'ca`', 'cadt', 'cat ', ';at', 'cat+', 'c&at', '?at', 'cbat', 'caq', 'cat\\\\', 'cato', 'caz', '}at', \"ca't\", 'aat', 'cta', 'cht', 'ctat', 'cat/', '&at', 'ca ', ',at', '\\\\cat', 'lat', ')at', 'cao', '|at', 'cpat', 'cat(', '*at', 'c-at', 'cot', 'c@at', 'ckat', 'c=at', \"c't\", 'cnat', 'car', 'cyat', 'cazt', 'c*at', '<cat', 'ca$t', 'cmt', 'c|at', '$at', 'ca?t', 'cat^', 'c)at', ']cat', '<at', 'c_t', 'clat', 'cast', 'cuat', 'crat', 'ca|', 'catc', 'rcat', 'c%t', 'ca$', 'catp', 'cact', 'ca]', 'ca[t', 'c!at', 'c=t', 'c]at', 'ca\"t', 'ca>t', 'cag', 'ct', 'cyt', 'c}t', 'cad', 'ca_t', '^cat', 'c`t', 'wcat', 'c-t', '>at', 'gcat', 'ca(', 'caa', 'ca#', 'czat', 'cate', 'crt', 'c<t', 'ca,', 'ca*t', 'iat', 'ca)t', 'cjat', 'cwt', 'ca?', '\"cat', 'cat[', 'mat', '+at', 'c(t', 'caty', 'cat-', 'cat!', 'cat:', 'catx', 'ncat', 'ca%t', '%at', 'ca=t', 'c\\\\at', 'c>t', 'ca+', 'ca<', '+cat', 'cut', 'ca!', '#cat', 'capt', 'cat&', 'cvat', '.cat'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlrfO58zCjxZ",
        "outputId": "16e7dc41-5ecd-4822-fe7f-f96fa62fb73c"
      },
      "source": [
        "word = \"USA\"\n",
        "distractors = sense2vec_get_words(word,s2v)\n",
        "\n",
        "print (\"Distractors for \",word, \" : \")\n",
        "print (distractors)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distractors for  USA  : \n",
            "['Usa.', 'U.S', 'U.S.', 'Us.', 'Us', 'America', 'Canada', 'U.S.A', 'United States', 'Country', 'Only Country', 'Mexico', 'Other Countries', 'U.K.', 'Europe', 'U.S.A.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkX5zgfyC6Q-",
        "outputId": "6cf890a4-46ba-4ab1-b8d3-69527c86903a"
      },
      "source": [
        "all_edits = edits (word.lower())\n",
        "print (all_edits)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'u%sa', 'usfa', 'uja', 'usa)', 'us{a', 'ssa', 'usa(', 'ysa', 'us\"', 'u\"a', 'uqsa', 'usa`', '^usa', 'csa', 'usf', \"'usa\", 'usa#', 'rusa', 'pusa', ';sa', '@usa', 'u-a', 'ufsa', 'uasa', 'us\\\\', 'us^a', 'usax', 'us>a', 'u.a', 'usa;', 'usa\\\\', 'us<a', 'dusa', 'u+a', '&usa', 'us$a', 'ujsa', '\\\\sa', 'u]sa', 'u@sa', 'qusa', 'usa]', 'u/sa', 'us-a', \"'sa\", 'usas', 'us:a', 'usa:', 'upa', 'u*sa', 'uta', 'sua', '{usa', '@sa', 'ksa', 'u?sa', '*usa', 'usq', 'u:sa', 'usw', 'umsa', 'usxa', 'usa_', 'uusa', 'usna', 'iusa', 'u=sa', 'us*', 'usva', \"us'\", 'uga', 'us~', 'isa', 'usau', 'usia', 'us/a', 'usao', 'us#a', 'u;a', 'usan', 'usb', 'usj', '^sa', 'us<', 'us ', 'us\"a', '|sa', '~sa', \"u'sa\", 'usa@', 'usah', 'u a', 'usa?', 'usay', 'uca', 'u\\\\sa', 'utsa', '{sa', ']sa', 'uza', 'usza', 'usca', 'us[a', 'wsa', '>usa', '|usa', 'usag', 'us_', 'u/a', '!usa', 'usm', 'us^', 'uaa', 'eusa', 'musa', 'usda', 'uxa', 'uqa', 'usoa', 'u*a', '.usa', 'u$sa', 'usma', 'us@a', 'uma', 'uva', 'u~sa', 'u(a', ')usa', 'usa', 'us}a', 'ula', 'u%a', 'us\\\\a', '&sa', '<sa', '`usa', 'u~a', '~usa', 'gsa', 'u&sa', '=sa', 'usl', '(usa', 'usaj', ' sa', 'usv', 'u!a', 'usa ', 'uba', 'usqa', 'ugsa', 'usav', 'us|a', '?usa', 'us=', 'rsa', 'u{sa', 'usae', 'u#a', 'yusa', '-usa', '}sa', 'usa>', 'nusa', 'ufa', 'usn', 'usua', 'usa\"', 'u)sa', 'us', '+sa', 'uska', ',usa', 'ua', \"usa'\", 'us]', 'usg', '\"usa', 'us,', 'u@a', 'us;', 'esa', 'us:', 'uzsa', 'nsa', 'husa', 'u\\\\a', 'us`a', 'u^sa', 'u`a', 'us!', 'us}', 'usya', 'busa', 'us*a', 'uas', 'us)a', 'u!sa', 'usha', 'u\"sa', 'us a', 'us&', 'us_a', 'u[sa', 'usa<', 'usa[', '$sa', 'u|a', '*sa', 'usea', '[usa', 'u,sa', 'fusa', 'u+sa', 'us>', 'u[a', 'ursa', '$usa', 'u>a', 'u:a', 'susa', '_usa', '[sa', 'usra', 'u,a', '_sa', 'usx', 'usr', 'zsa', 'u)a', 'tusa', 'xsa', 'ausa', 'usta', 'u>sa', 'us.a', 'psa', '!sa', 'usga', 'usu', 'us.', 'us#', 'us/', '}usa', 'us$', 'us~a', 'u_sa', 'us%', 'uka', 'usaz', 'usz', 'us,a', 'lsa', 'u}a', 'uvsa', 'msa', 'ust', 'use', 'u#sa', 'us]a', 'usa{', 'usba', 'usa+', ';usa', 'u(sa', 'usak', ':usa', 'jsa', 'sa', 'uea', 'usi', 'usad', 'cusa', 'u=a', ']usa', '>sa', 'u}sa', 'bsa', 'uwsa', 'xusa', 'uso', \"u'a\", ':sa', '\"sa', '(sa', 'usam', ' usa', 'usa}', 'us%a', '#usa', 'kusa', 'u^a', 'u;sa', 'dsa', 'una', 'uksa', 'usaw', ')sa', 'jusa', 'usaf', 'u<a', 'udsa', 'usa~', 'us{', 'u.sa', 'u?a', 'us+a', 'u]a', 'vusa', '=usa', 'u`sa', 'us;a', 'uda', 'us@', 'zusa', 'unsa', 'u{a', 'usk', 'uoa', 'uysa', 'u$a', 'uua', 'usaa', 'ura', 'uia', 'u-sa', 'us=a', 'us[', 'usa.', 'us`', 'usa|', 'ubsa', 'usa^', 'usa/', 'u|sa', 'u<sa', '\\\\usa', 'lusa', '.sa', 'us-', 'uosa', 'usa$', 'us?a', 'ousa', 'uxsa', 'us&a', 'usc', 'usp', 'u_a', '%usa', 'ush', \"us'a\", 'usac', 'usal', 'us+', 'usaq', 'usja', '/usa', '?sa', 'uspa', 'us!a', '`sa', 'us(', 'u&a', 'hsa', '/sa', '<usa', 'us|', 'ucsa', 'usat', 'gusa', 'us?', 'uesa', 'upsa', ',sa', 'uisa', 'usai', 'uya', '-sa', 'us)', '%sa', 'usa*', 'osa', 'usa!', 'uss', 'usab', 'uswa', 'qsa', '+usa', 'u sa', 'tsa', 'fsa', 'uha', 'wusa', 'usy', 'usa=', 'ulsa', 'usa&', 'asa', 'usa-', 'usd', 'usap', 'ussa', 'vsa', 'usla', 'usa,', 'usar', 'uhsa', 'uwa', 'usa%', 'us(a', '#sa'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajw2cxsbC93H",
        "outputId": "47471a7a-8f51-4a7b-a0f6-7029f089c8e7"
      },
      "source": [
        "filtered_distractors_edit_distance = [x for x in distractors if x.lower() not in all_edits]\n",
        "print (filtered_distractors_edit_distance)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['U.S', 'U.S.', 'America', 'Canada', 'U.S.A', 'United States', 'Country', 'Only Country', 'Mexico', 'Other Countries', 'U.K.', 'Europe', 'U.S.A.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjgaK5WgDF1X"
      },
      "source": [
        "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
        "normalized_levenshtein = NormalizedLevenshtein()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIJ6LKjFDePD",
        "outputId": "aec67f0b-3d9f-4476-9e57-45e803b98d1f"
      },
      "source": [
        "\n",
        "print (\"Levenshtein Distance USA  & U.S.A  ->\", normalized_levenshtein.distance(\"USA\",\"U.S.A\"))\n",
        "print (\"Levenshtein Distance USA  & U.S  ->\", normalized_levenshtein.distance(\"USA\",\"U.S\"))\n",
        "print (\"Levenshtein Distance USA  & America  ->\", normalized_levenshtein.distance(\"USA\",\"America\"))\n",
        "print (\"Levenshtein Distance USA  & Canada  ->\", normalized_levenshtein.distance(\"USA\",\"Canada\"))\n",
        "print (\"Levenshtein Distance USA  & United States  ->\", normalized_levenshtein.distance(\"USA\",\"United States\"))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Levenshtein Distance USA  & U.S.A  -> 0.4\n",
            "Levenshtein Distance USA  & U.S  -> 0.6666666666666666\n",
            "Levenshtein Distance USA  & America  -> 1.0\n",
            "Levenshtein Distance USA  & Canada  -> 1.0\n",
            "Levenshtein Distance USA  & United States  -> 0.8461538461538461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyf9p2hKDgEf",
        "outputId": "a06058e3-39b1-4282-d3c3-34bffe7d9382"
      },
      "source": [
        "threshold = 0.7\n",
        "filtered_distractors_edit_distance_and_levenshtein_distance =[[x for x in filtered_distractors_edit_distance if normalized_levenshtein.distance(x.lower(),word.lower())>threshold] ]\n",
        "print (filtered_distractors_edit_distance_and_levenshtein_distance)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['America', 'Canada', 'United States', 'Country', 'Only Country', 'Mexico', 'Other Countries', 'U.K.', 'Europe']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiziRYCWDkNA",
        "outputId": "1a24eaf9-1a6d-471e-8e0f-07b62bf0c542"
      },
      "source": [
        "print (distractors)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Usa.', 'U.S', 'U.S.', 'Us.', 'Us', 'America', 'Canada', 'U.S.A', 'United States', 'Country', 'Only Country', 'Mexico', 'Other Countries', 'U.K.', 'Europe', 'U.S.A.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8F19tBBDspJ"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}